{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f298157",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from scipy.spatial import distance_matrix\n",
    "import pathlib, sys, os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,balanced_accuracy_score,precision_score,f1_score,silhouette_score,recall_score,classification_report,confusion_matrix\n",
    "from scipy.stats import ttest_ind\n",
    "from mpl_toolkits.mplot3d import Axes3D   \n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "from scipy.stats import spearmanr,pearsonr, ttest_ind\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nilearn import plotting\n",
    "from scipy.ndimage import gaussian_filter\n",
    "display(HTML(\n",
    "    '<style>'\n",
    "        '#notebook { padding-top:0px !important; } ' \n",
    "        '.container { width:100% !important; } '\n",
    "        '.end_space { min-height:0px !important; } '\n",
    "        '#notebook-container {padding: 0px;}'\n",
    "    '</style>'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed869e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "043abf29",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaef07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"T1_ADVDLBD_Mlabel_10fold_0307v2\"\n",
    "pth_nii = '/media/dw/Data/BINC_T1/BINC/dropbox/nacc_harmonized_may023/beforeHarm_3DSminmax/'\n",
    "pth = \"/home/dw/Desktop/DemCLF/data/data_Mlabel_10fold_0307/\"\n",
    "mri_IDs = []\n",
    "save_folder = '/media/dw/Data/BINC_T1/BINC/dropbox/DW/data_npy/T1_3DSminmax_ADVDLBD_Mlabel_10fold_0307v2/'\n",
    "pathlib.Path(save_folder).mkdir(parents=True, exist_ok=True)\n",
    "print(save_folder)\n",
    "\n",
    "for fold in range(0,10):\n",
    "    df_train = pd.read_csv(pth + data_name + \"_train_f\" + str(fold) + \".csv\")\n",
    "    X_train,y_train = [],[]\n",
    "    for i,r in df_train.iterrows():\n",
    "        name = r['mri_ID']\n",
    "        niia = nib.load(pth_nii + name).get_fdata().flatten()\n",
    "        X_train.append(niia)\n",
    "        y_train.append(r[['AD','VD','LBD']].tolist())\n",
    "    np.save(save_folder+\"/X_train_f\" + str(fold)+\".npy\",X_train)\n",
    "    np.save(save_folder+\"/y_train_f\" + str(fold)+\".npy\",y_train)\n",
    "    \n",
    "    df_test = pd.read_csv(pth + data_name + \"_test_f\" + str(fold) + \".csv\")\n",
    "    X_test,y_test = [],[]\n",
    "    for i,r in df_test.iterrows():\n",
    "        name = r['mri_ID']\n",
    "        niia = nib.load(pth_nii + name).get_fdata().flatten()\n",
    "        X_test.append(niia)\n",
    "        y_test.append(r[['AD','VD','LBD']].tolist())\n",
    "        mri_IDs.append(name)\n",
    "    np.save(save_folder+\"/X_test_f\" + str(fold)+\".npy\",X_test)\n",
    "    np.save(save_folder+\"/y_test_f\" + str(fold)+\".npy\",y_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"T1_ADVDLBD_Mlabel_10fold_0307v2\"\n",
    " \n",
    "pth = \"/home/dw/Desktop/DemCLF/data/data_Mlabel_10fold_0307/\"\n",
    "mri_IDs = []\n",
    "\n",
    "for fold in range(0,10):\n",
    "    df_test = pd.read_csv(pth + data_name + \"_test_f\" + str(fold) + \".csv\")\n",
    "    X_test,y_test = [],[]\n",
    "    for i,r in df_test.iterrows():\n",
    "        name = r['mri_ID']\n",
    "        mri_IDs.append(name)\n",
    "mri_IDs = [i[0:19] for i in mri_IDs]\n",
    "len(mri_IDs)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fcdd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa71167d",
   "metadata": {},
   "source": [
    "# 3DS RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33220815",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/media/dw/Data/BINC_T1/BINC/dropbox/DW/data_npy/T1_3DSminmax_ADVDLBD_Mlabel_10fold_0307v2/'\n",
    "save_folder = '/media/dw/Data/BINC_T1/BINC/dropbox/DW/data_npy/T1_3DSminmax_ADVDLBD_Mlabel_10fold_0307v2/RF/'\n",
    "pathlib.Path(save_folder).mkdir(parents=True, exist_ok=True)\n",
    "print(save_folder)\n",
    "\n",
    "for n_estimators in [20,50,100,200,300,400]: #,50,100,200,300,400\n",
    "    all_t = []\n",
    "    all_p = []\n",
    "    all_probAD = []\n",
    "    all_probVD = []\n",
    "    all_probOD = []\n",
    "    \n",
    "    for fold in range(0,10):\n",
    "        X_train = np.load(data_folder + \"/X_train_f\" + str(fold)+\".npy\")\n",
    "        y_train = np.load(data_folder + \"/y_train_f\" + str(fold)+\".npy\")\n",
    "\n",
    "        X_test = np.load(data_folder + \"/X_test_f\" + str(fold)+\".npy\")\n",
    "        y_test = np.load(data_folder + \"/y_test_f\" + str(fold)+\".npy\")\n",
    "\n",
    "\n",
    "\n",
    "        clf =RandomForestClassifier(n_estimators = n_estimators).fit(X_train, y_train)\n",
    "        y_predict = clf.predict(X_test)\n",
    "        all_p.extend(y_predict)\n",
    "        all_t.extend(y_test)\n",
    "        y_prob = clf.predict_proba(X_test)\n",
    "        all_probAD.extend(y_prob[0][:,1])\n",
    "        all_probVD.extend(y_prob[1][:,1])\n",
    "        all_probOD.extend(y_prob[2][:,1])\n",
    "\n",
    "\n",
    "    all_p = np.array(all_p)\n",
    "    all_t = np.array(all_t)\n",
    "\n",
    "\n",
    "\n",
    "    ac1 = precision_score(all_t, all_p, average='micro',zero_division =0)\n",
    "    ac2 = recall_score(all_t, all_p, average='micro')\n",
    "    ac3 = f1_score(all_t, all_p, average='micro')\n",
    "    ac4 = balanced_accuracy_score(all_t[:,0],all_p[:,0])\n",
    "    ac5 = balanced_accuracy_score(all_t[:,1],all_p[:,1])\n",
    "    ac6 = balanced_accuracy_score(all_t[:,2],all_p[:,2])\n",
    "    ac7 = (ac4 + ac5+ ac6)/3\n",
    "    # ac7 = (ac4 + ac5)/2\n",
    "    print(\"\\n #### Random Forest, n_estimators=\"+str(n_estimators))\n",
    "    print('precision',np.round(ac1,3))\n",
    "    print('recall',np.round(ac2,3))\n",
    "    print('F1',np.round(ac3,3))\n",
    "    print('AD acc',np.round(ac4,3))\n",
    "    print('VD acc',np.round(ac5,3))\n",
    "    print('LBD acc',np.round(ac6,3))\n",
    "    print('AVE acc',np.round(ac7,3))\n",
    "    \n",
    "    df = pd.DataFrame(all_t, columns = ['AD','VD','LBD'])\n",
    "    df.insert(loc = 2, column = 'probVD',value = all_probVD)\n",
    "    df.insert(loc = 2, column = 'probAD',value = all_probAD)\n",
    "    df.insert(loc = 2, column = 'probLBD',value = all_probOD)\n",
    "    df.insert(loc = 4, column = 'VD_pred',value = np.array(all_p)[:,0])\n",
    "    df.insert(loc = 4, column = 'AD_pred',value = np.array(all_p)[:,1])\n",
    "    df.insert(loc = 4, column = 'LBD_pred',value = np.array(all_p)[:,2])\n",
    "    df.insert(loc = 0, column = 'mri_ID',value = mri_IDs)\n",
    "    df.to_csv(save_folder+\"/RF_prob_n\"+str(n_estimators)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 300\n",
    "df = pd.read_csv(\"/media/dw/Data/BINC_T1/BINC/dropbox/DW/data_npy/T1_3DSminmax_ADVDLBD_Mlabel_10fold_0307v2/RF/RF_prob_n\"+str(n_estimators)+\".csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11fca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(ncols = 3,nrows=1,figsize = (15,5))\n",
    "axs = axs.flatten()\n",
    "\n",
    "\n",
    "s = 150    \n",
    "f1,f2 ='probAD','probVD'\n",
    "\n",
    "fs = 20\n",
    "\n",
    "# axs[0].scatter(-100,-100, label = \"CN\", marker='o', alpha = 0.5, s =40, color = 'gray')\n",
    "# axs[0].scatter(-100,-100, label = \"AD\", marker='>', alpha = 0.5, s =s, color = '#2CA02C')\n",
    "# axs[0].scatter(-100,-100, label = \"VD\", marker='<', alpha = 0.5, s =s, color = '#D62728')\n",
    "# axs[0].scatter(-100,-100, label = \"LBD\", marker='^', alpha = 0.5, s =s, color = 'blue')\n",
    "# axs[0].scatter(-100,-100, label = \"AD+VD\", marker='+', alpha = 0.5, s =s+100, color = 'violet')\n",
    "# axs[0].scatter(-100,-100, label = \"AD+LBD\", marker='+', alpha = 0.5, s =s+100, color = 'purple')\n",
    "# axs[0].scatter(-100,-100, label = \"VD+LBD\", marker='+', alpha = 0.5, s =s+100, color = 'magenta')\n",
    "# axs[0].scatter(-100,-100, label = \"AD+VD+LBD\", marker='x', alpha = 0.5, s =s, color = 'goldenrod')\n",
    "# axs[0].legend(prop={'size': 20},bbox_to_anchor=(1, 0.53, 0.5, 0.5))\n",
    "\n",
    "axs[0].scatter(df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 0)][[f1]],\n",
    "            df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 0)][[f2]], \n",
    "             marker='o', alpha = 0.3, s =40, color = 'gray')\n",
    "\n",
    "axs[0].scatter(df.loc[(df['AD'] == 1) &(df['VD'] == 1)&(df['LBD'] == 0)][[f1]],\n",
    "            df.loc[(df['AD'] == 1) &(df['VD'] == 1)&(df['LBD'] == 0)][[f2]], \n",
    "             marker='+', alpha = 0.5, s =s+100, color = 'violet')\n",
    "\n",
    "axs[0].scatter(df.loc[(df['AD'] == 1) &(df['VD'] == 1)&(df['LBD'] == 1)][[f1]],\n",
    "            df.loc[(df['AD'] == 1) &(df['VD'] == 1)&(df['LBD'] == 1)][[f2]], \n",
    "            marker='x', alpha = 0.5, s =s, color = 'goldenrod')\n",
    "axs[0].scatter(df.loc[(df['AD'] == 0) &(df['VD'] == 1)&(df['LBD'] == 0)][[f1]],\n",
    "            df.loc[(df['AD'] == 0) &(df['VD'] == 1)&(df['LBD'] == 0)][[f2]], \n",
    "             marker='<', alpha = 0.5, s =s, color = '#D62728')\n",
    "\n",
    "axs[0].scatter(df.loc[(df['AD'] == 1) &(df['VD'] == 0)&(df['LBD'] == 0)][[f1]],\n",
    "            df.loc[(df['AD'] == 1) &(df['VD'] == 0)&(df['LBD'] == 0)][[f2]], \n",
    "             marker='>', alpha = 0.5, s =s, color = '#2CA02C')\n",
    "\n",
    "axs[0].set_xlabel(r'$\\bf{AD}$ Probability', fontsize = fs)\n",
    "axs[0].set_ylabel(r'$\\bf{VD}$ Probability', fontsize = fs)    \n",
    "\n",
    "\n",
    "\n",
    "f1,f2 ='probAD','probLBD'\n",
    "axs[1].scatter(df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 0)][[f1]],\n",
    "            df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 0)][[f2]], \n",
    "            marker='o', alpha = 0.3, s =40, color = 'gray')\n",
    "\n",
    "axs[1].scatter(df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 1)][[f1]],\n",
    "            df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 1)][[f2]], \n",
    "             marker='^', alpha = 0.5, s =s, color = 'blue')\n",
    "\n",
    "axs[1].scatter(df.loc[(df['AD'] == 1) &(df['VD'] == 0)&(df['LBD'] == 0)][[f1]],\n",
    "            df.loc[(df['AD'] == 1) &(df['VD'] == 0)&(df['LBD'] == 0)][[f2]], \n",
    "            marker='>', alpha = 0.5, s =s, color = 'green')\n",
    "\n",
    "axs[1].scatter(df.loc[(df['AD'] == 1) &(df['VD'] == 0)&(df['LBD'] == 1)][[f1]],\n",
    "            df.loc[(df['AD'] == 1) &(df['VD'] == 0)&(df['LBD'] == 1)][[f2]], \n",
    "             marker='+', alpha = 0.5, s =s+100, color = 'purple')\n",
    "\n",
    "axs[1].scatter(df.loc[(df['AD'] == 1) &(df['VD'] == 1)&(df['LBD'] == 1)][[f1]],\n",
    "            df.loc[(df['AD'] == 1) &(df['VD'] == 1)&(df['LBD'] == 1)][[f2]], \n",
    "             marker='x', alpha = 0.5, s =s, color = 'goldenrod')\n",
    "\n",
    "axs[1].set_xlabel(r'$\\bf{AD}$ Probability', fontsize = fs)\n",
    "axs[1].set_ylabel(r'$\\bf{LBD}$ Probability', fontsize = fs) \n",
    "\n",
    "\n",
    "f1,f2 ='probVD','probLBD'\n",
    "axs[2].scatter(df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 0)][[f1]],\n",
    "            df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 0)][[f2]], \n",
    "            marker='o', alpha = 0.3, s =40, color = 'gray')\n",
    "\n",
    "axs[2].scatter(df.loc[(df['AD'] == 0) &(df['VD'] == 1)&(df['LBD'] == 0)][[f1]],\n",
    "            df.loc[(df['AD'] == 0) &(df['VD'] == 1)&(df['LBD'] == 0)][[f2]], \n",
    "            marker='<', alpha = 0.5, s =s, color = '#D62728')\n",
    "\n",
    "axs[2].scatter(df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 1)][[f1]],\n",
    "            df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 1)][[f2]], \n",
    "            marker='^', alpha = 0.5, s =s, color = 'blue')\n",
    "\n",
    "axs[2].scatter(df.loc[(df['AD'] == 0) &(df['VD'] == 1)&(df['LBD'] == 1)][[f1]],\n",
    "            df.loc[(df['AD'] == 0) &(df['VD'] == 1)&(df['LBD'] == 1)][[f2]], \n",
    "             marker='+', alpha = 0.5, s =s+100, color = 'magenta')\n",
    "\n",
    "axs[2].scatter(df.loc[(df['AD'] == 1) &(df['VD'] == 1)&(df['LBD'] == 1)][[f1]],\n",
    "            df.loc[(df['AD'] == 1) &(df['VD'] == 1)&(df['LBD'] == 1)][[f2]], \n",
    "             marker='x', alpha = 0.5, s =s, color = 'goldenrod')\n",
    "\n",
    "axs[2].set_xlabel( r'$\\bf{VD}$ Probability', fontsize = fs)\n",
    "axs[2].set_ylabel(r'$\\bf{LBD}$ Probability', fontsize = fs)\n",
    "    \n",
    "\n",
    "\n",
    "# plt.xlim([-0.05,1.05])\n",
    "# plt.ylim([-0.05,1.05])\n",
    "# plt.gca().set_yticklabels([f'{x:.0%}' for x in plt.gca().get_yticks()]) \n",
    "# plt.gca().set_xticklabels([f'{x:.0%}' for x in plt.gca().get_xticks()]) \n",
    "\n",
    "# axs[0].set_title(\"Deep Learning Chart\", fontsize = 20)\n",
    "# plt.grid(linestyle = '--')\n",
    "for i in range(0,3):\n",
    "    axs[i].axvline(x = 0.5, linestyle = '--', color='gray', alpha = 0.5)\n",
    "    axs[i].axhline(y = 0.5, linestyle = '--', color='gray', alpha = 0.5)\n",
    "    axs[i].set_xlim([-0.05,1.05])\n",
    "    axs[i].set_ylim([-0.05,1.05])\n",
    "    \n",
    "for i in range(0,3):    \n",
    "    axs[i].set_yticklabels([f'{x:.0%}' for x in plt.gca().get_yticks()], fontsize=12) \n",
    "    axs[i].set_xticklabels([f'{x:.0%}' for x in plt.gca().get_xticks()], fontsize=12) \n",
    "\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91972295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f956fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3193bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3825f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(df.AD.values.tolist(), df.probAD.values.tolist())\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "fpr2, tpr2, threshold2 = metrics.roc_curve(df.VD.values.tolist(), df.probVD.values.tolist())\n",
    "roc_auc2 = metrics.auc(fpr2, tpr2)\n",
    "\n",
    "fpr3, tpr3, threshold3 = metrics.roc_curve(df.LBD.values.tolist(), df.probLBD.values.tolist())\n",
    "roc_auc3 = metrics.auc(fpr3, tpr3)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.title('Random Forest', fontsize = 20)\n",
    "plt.plot(fpr, tpr, 'g', label = 'AD AUC = %0.2f' % roc_auc)\n",
    "plt.plot(fpr2, tpr2, 'r', label = 'VD AUC = %0.2f' % roc_auc2)\n",
    "plt.plot(fpr3, tpr3, 'b', label = 'LBD AUC = %0.2f' % roc_auc3)\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'y--')\n",
    "# plt.xlim([0, 1])\n",
    "# plt.ylim([0, 1])\n",
    "plt.grid(linestyle = '--')\n",
    "plt.ylabel('True Positive Rate', fontsize = 15)\n",
    "plt.xlabel('False Positive Rate', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cef1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f96e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77653db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
