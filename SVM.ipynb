{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5934c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from scipy.spatial import distance_matrix\n",
    "import pathlib\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.metrics import accuracy_score,balanced_accuracy_score,precision_score,f1_score,silhouette_score,recall_score,classification_report,confusion_matrix\n",
    "from scipy.stats import ttest_ind\n",
    "from mpl_toolkits.mplot3d import Axes3D   \n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "from scipy.stats import spearmanr,pearsonr, ttest_ind\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nilearn import plotting\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "display(HTML(\n",
    "    '<style>'\n",
    "        '#notebook { padding-top:0px !important; } ' \n",
    "        '.container { width:100% !important; } '\n",
    "        '.end_space { min-height:0px !important; } '\n",
    "        '#notebook-container {padding: 0px;}'\n",
    "    '</style>'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd16495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9de56f5",
   "metadata": {},
   "source": [
    "# MultiOutputClassifier SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6614fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/media/dw/Data/BINC_T1/BINC/dropbox/DW/data_npy/T1_3DSminmax_ADVDLBD_Mlabel_10fold_0307v2/'\n",
    "save_folder = '/media/dw/Data/BINC_T1/BINC/dropbox/DW/data_npy/T1_3DSminmax_ADVDLBD_Mlabel_10fold_0307v2/SVM/'\n",
    "pathlib.Path(save_folder).mkdir(parents=True, exist_ok=True)\n",
    "print(save_folder)\n",
    "\n",
    "for c in [10,1,0.1,0.01,0.001,0.0001]:\n",
    "    all_t = []\n",
    "    all_p = []\n",
    "\n",
    "    for fold in range(0,10):\n",
    "        X_train = np.load(data_folder + \"/X_train_f\" + str(fold)+\".npy\")\n",
    "        y_train = np.load(data_folder + \"/y_train_f\" + str(fold)+\".npy\")\n",
    "\n",
    "        X_test = np.load(data_folder + \"/X_test_f\" + str(fold)+\".npy\")\n",
    "        y_test = np.load(data_folder + \"/y_test_f\" + str(fold)+\".npy\")\n",
    "\n",
    "        clf = MultiOutputClassifier(SVC(C=c,kernel = 'linear')).fit(X_train, y_train)\n",
    "\n",
    "        y_predict = clf.predict(X_test)\n",
    "        all_p.extend(y_predict)\n",
    "        all_t.extend(y_test)\n",
    "\n",
    "    all_p = np.array(all_p)\n",
    "    all_t = np.array(all_t)\n",
    "    \n",
    "    np.save(save_folder+\"/SVM_c\"+ str(c) + \"_all_p.npy\", all_p)\n",
    "    np.save(save_folder+\"/SVM_c\"+ str(c) + \"_all_t.npy\", all_t)\n",
    "\n",
    "    ac1 = precision_score(all_t, all_p, average='micro',zero_division =0)\n",
    "    ac2 = recall_score(all_t, all_p, average='micro')\n",
    "    ac3 = f1_score(all_t, all_p, average='micro')\n",
    "    ac4 = balanced_accuracy_score(all_t[:,0],all_p[:,0]) \n",
    "    ac5 = balanced_accuracy_score(all_t[:,1],all_p[:,1])\n",
    "    ac6 = balanced_accuracy_score(all_t[:,2],all_p[:,2])\n",
    "    ac7 = (ac4 + ac5 + ac6)/3\n",
    "    print(\"#### MultiOutputClassifier, SVM-linear c=\" + str(c))\n",
    "    print('precision',np.round(ac1,2))\n",
    "    print('recall',np.round(ac2,2))\n",
    "    print('F1',np.round(ac3,2))\n",
    "    print('AD acc',np.round(ac4,2))\n",
    "    print('VD acc',np.round(ac5,2))\n",
    "    print('LBD acc',np.round(ac6,2))\n",
    "    print('AVE acc',np.round(ac7,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21719b58",
   "metadata": {},
   "source": [
    "# Get Prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633445b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"T1_ADVDLBD_Mlabel_10fold_0307v2\"\n",
    " \n",
    "pth = \"/home/dw/Desktop/DemCLF/data/data_Mlabel_10fold_0307/\"\n",
    "mri_IDs = []\n",
    "\n",
    "for fold in range(0,10):\n",
    "    df_test = pd.read_csv(pth + data_name + \"_test_f\" + str(fold) + \".csv\")\n",
    "    X_test,y_test = [],[]\n",
    "    for i,r in df_test.iterrows():\n",
    "        name = r['mri_ID']\n",
    "        mri_IDs.append(name)\n",
    "mri_IDs = [i[0:19] for i in mri_IDs]\n",
    "len(mri_IDs)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e0cd5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = 0.01\n",
    "\n",
    "\n",
    "ids = []\n",
    "\n",
    "data_folder = '/media/dw/Data/BINC_T1/BINC/dropbox/DW/data_npy/T1_3DSminmax_ADVDLBD_Mlabel_10fold_0307v2/'\n",
    "save_folder = '/media/dw/Data/BINC_T1/BINC/dropbox/DW/data_npy/T1_3DSminmax_ADVDLBD_Mlabel_10fold_0307v2/SVM/'\n",
    "for fold in range(0,10):\n",
    "    print(fold)\n",
    "    all_t = []\n",
    "    all_p = []\n",
    "    all_ad_prob = []\n",
    "    all_vd_prob = []\n",
    "    all_lbd_prob = []\n",
    "    X_train = np.load(data_folder+\"/X_train_f\" + str(fold)+\".npy\")\n",
    "    y_train = np.load(data_folder+\"/y_train_f\" + str(fold)+\".npy\")\n",
    "    \n",
    "    X_test = np.load(data_folder+\"/X_test_f\" + str(fold)+\".npy\")\n",
    "    y_test = np.load(data_folder+\"/y_test_f\" + str(fold)+\".npy\")\n",
    "    \n",
    "    clf = MultiOutputClassifier(SVC(C=c,kernel = 'linear',probability=True, max_iter = 10000)).fit(X_train, y_train)\n",
    "    ad_coef = clf.estimators_[0].coef_[0]\n",
    "    vd_coef = clf.estimators_[1].coef_[0]\n",
    "    lbd_coef = clf.estimators_[2].coef_[0]\n",
    "\n",
    "    y_predict = clf.predict(X_test)\n",
    "    all_p.extend(y_predict)\n",
    "    all_t.extend(y_test)\n",
    "    \n",
    "    \n",
    "    all_ad_prob.extend(clf.estimators_[0].predict_proba(X_test)[:,1])\n",
    "    all_vd_prob.extend(clf.estimators_[1].predict_proba(X_test)[:,1])\n",
    "    all_lbd_prob.extend(clf.estimators_[2].predict_proba(X_test)[:,1])\n",
    "    \n",
    "    all_p = np.array(all_p)\n",
    "    all_t = np.array(all_t)\n",
    "\n",
    "    np.save(save_folder+\"/SVM_c\"+ str(c) + \"_all_p\"+str(fold)+\".npy\", all_p)\n",
    "    np.save(save_folder+\"/SVM_c\"+ str(c) + \"_all_t\"+str(fold)+\".npy\", all_t)\n",
    "\n",
    "    \n",
    "    np.save(save_folder+\"/SVM_c\"+ str(c) + \"_ad\"+str(fold)+\".npy\", all_ad_prob)\n",
    "    np.save(save_folder+\"/SVM_c\"+ str(c) + \"_vd\"+str(fold)+\".npy\", all_vd_prob)\n",
    "    np.save(save_folder+\"/SVM_c\"+ str(c) + \"_lbd\"+str(fold)+\".npy\", all_lbd_prob)\n",
    "\n",
    "\n",
    "    np.save(save_folder+\"/SVM_c\"+ str(c) + \"_ad_coef\"+str(fold)+\".npy\", ad_coef)\n",
    "    np.save(save_folder+\"/SVM_c\"+ str(c) + \"_vd_coef\"+str(fold)+\".npy\", vd_coef)\n",
    "    np.save(save_folder+\"/SVM_c\"+ str(c) + \"_lbd_coef\"+str(fold)+\".npy\", lbd_coef)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "save_folder = '/media/dw/Data/BINC_T1/BINC/dropbox/DW/data_npy/T1_3DSminmax_ADVDLBD_Mlabel_10fold_0307v2/SVM/'\n",
    "# c = 0.01\n",
    "# all_t = []\n",
    "# all_p = []\n",
    "# all_ad_prob = []\n",
    "# all_vd_prob = []\n",
    "# all_lbd_prob = []\n",
    "# for fold in range(0,10):\n",
    "#     all_p.extend(np.load(save_folder+\"/SVM_c\"+ str(c) + \"_all_p\"+str(fold)+\".npy\"))\n",
    "#     all_t.extend(np.load(save_folder+\"/SVM_c\"+ str(c) + \"_all_t\"+str(fold)+\".npy\"))\n",
    "\n",
    "    \n",
    "#     all_ad_prob.extend(np.load(save_folder+\"/SVM_c\"+ str(c) + \"_ad\"+str(fold)+\".npy\"))\n",
    "#     all_vd_prob.extend(np.load(save_folder+\"/SVM_c\"+ str(c) + \"_vd\"+str(fold)+\".npy\"))\n",
    "#     all_lbd_prob.extend(np.load(save_folder+\"/SVM_c\"+ str(c) + \"_lbd\"+str(fold)+\".npy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7121503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_t, columns = ['AD', 'VD', 'LBD'])\n",
    "df2 = pd.DataFrame(all_p, columns = ['ADp', 'VDp', 'LBDp'])\n",
    "df = pd.concat([df,df2],axis = 1)\n",
    "df.insert(loc = 6, column = 'probLBD', value = all_lbd_prob)\n",
    "df.insert(loc = 6, column = 'probVD', value = all_vd_prob)\n",
    "df.insert(loc = 6, column = 'probAD', value = all_ad_prob)\n",
    "df.insert(loc = 0, column = 'mri_ID',value = mri_IDs)\n",
    "df\n",
    "df.to_csv(save_folder+\"/SVM_c\"+ str(c) + \"_prob.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12611851",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0.01\n",
    "save_folder = '/media/dw/Data/BINC_T1/BINC/dropbox/DW/data_npy/T1_3DSminmax_ADVDLBD_Mlabel_10fold_0307v2/SVM/'\n",
    "\n",
    "df = pd.read_csv(save_folder+\"/SVM_c\"+ str(c) + \"_prob.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac9cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_t = df[['AD', 'VD', 'LBD']].values\n",
    "all_p = df[['ADp', 'VDp', 'LBDp']].values\n",
    "\n",
    "ac1 = precision_score(all_t, all_p, average='micro',zero_division =0)\n",
    "ac2 = recall_score(all_t, all_p, average='micro')\n",
    "ac3 = f1_score(all_t, all_p, average='micro')\n",
    "ac4 = balanced_accuracy_score(all_t[:,0],all_p[:,0]) \n",
    "ac5 = balanced_accuracy_score(all_t[:,1],all_p[:,1])\n",
    "ac6 = balanced_accuracy_score(all_t[:,2],all_p[:,2])\n",
    "ac7 = (ac4 + ac5 + ac6)/3\n",
    "print('precision',np.round(ac1,3))\n",
    "print('recall',np.round(ac2,3))\n",
    "print('F1',np.round(ac3,3))\n",
    "print('AD acc',np.round(ac4,3))\n",
    "print('VD acc',np.round(ac5,3))\n",
    "print('LBD acc',np.round(ac6,3))\n",
    "print('AVE acc',np.round(ac7,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375bd313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a953738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c83f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af7ee17f",
   "metadata": {},
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(df.AD.values.tolist(), df.probAD.values.tolist())\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "fpr2, tpr2, threshold2 = metrics.roc_curve(df.VD.values.tolist(), df.probVD.values.tolist())\n",
    "roc_auc2 = metrics.auc(fpr2, tpr2)\n",
    "\n",
    "fpr3, tpr3, threshold3 = metrics.roc_curve(df.LBD.values.tolist(), df.probLBD.values.tolist())\n",
    "roc_auc3 = metrics.auc(fpr3, tpr3)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.title('Ensemble SVM', fontsize = 20)\n",
    "plt.plot(fpr, tpr, 'g', label = 'AD AUC = %0.2f' % roc_auc)\n",
    "plt.plot(fpr2, tpr2, 'r', label = 'VD AUC = %0.2f' % roc_auc2)\n",
    "plt.plot(fpr3, tpr3, 'b', label = 'LBD AUC = %0.2f' % roc_auc3)\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'y--')\n",
    "# plt.xlim([0, 1])\n",
    "# plt.ylim([0, 1])\n",
    "plt.grid(linestyle = '--')\n",
    "plt.ylabel('True Positive Rate', fontsize = 15)\n",
    "plt.xlabel('False Positive Rate', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e995108f",
   "metadata": {},
   "source": [
    "# Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c8e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(ncols = 3,nrows=1,figsize = (15,5))\n",
    "axs = axs.flatten()\n",
    "\n",
    "\n",
    "s = 150    \n",
    "f1,f2 ='probAD','probVD'\n",
    "\n",
    "fs = 20\n",
    "\n",
    "# axs[0].scatter(-100,-100, label = \"CN\", marker='o', alpha = 0.5, s =40, color = 'gray')\n",
    "# axs[0].scatter(-100,-100, label = \"AD\", marker='>', alpha = 0.5, s =s, color = '#2CA02C')\n",
    "# axs[0].scatter(-100,-100, label = \"VD\", marker='<', alpha = 0.5, s =s, color = '#D62728')\n",
    "# axs[0].scatter(-100,-100, label = \"LBD\", marker='^', alpha = 0.5, s =s, color = 'blue')\n",
    "# axs[0].scatter(-100,-100, label = \"AD+VD\", marker='+', alpha = 0.5, s =s+100, color = 'violet')\n",
    "# axs[0].scatter(-100,-100, label = \"AD+LBD\", marker='+', alpha = 0.5, s =s+100, color = 'purple')\n",
    "# axs[0].scatter(-100,-100, label = \"VD+LBD\", marker='+', alpha = 0.5, s =s+100, color = 'magenta')\n",
    "# axs[0].scatter(-100,-100, label = \"AD+VD+LBD\", marker='x', alpha = 0.5, s =s, color = 'goldenrod')\n",
    "# axs[0].legend(prop={'size': 20},bbox_to_anchor=(1, 0.53, 0.5, 0.5))\n",
    "\n",
    "axs[0].scatter(df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 0)][[f1]],\n",
    "            df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 0)][[f2]], \n",
    "             marker='o', alpha = 0.3, s =40, color = 'gray')\n",
    "\n",
    "axs[0].scatter(df.loc[(df['AD'] == 1) &(df['VD'] == 1)&(df['LBD'] == 0)][[f1]],\n",
    "            df.loc[(df['AD'] == 1) &(df['VD'] == 1)&(df['LBD'] == 0)][[f2]], \n",
    "             marker='+', alpha = 0.5, s =s+100, color = 'violet')\n",
    "\n",
    "axs[0].scatter(df.loc[(df['AD'] == 1) &(df['VD'] == 1)&(df['LBD'] == 1)][[f1]],\n",
    "            df.loc[(df['AD'] == 1) &(df['VD'] == 1)&(df['LBD'] == 1)][[f2]], \n",
    "            marker='x', alpha = 0.5, s =s, color = 'goldenrod')\n",
    "axs[0].scatter(df.loc[(df['AD'] == 0) &(df['VD'] == 1)&(df['LBD'] == 0)][[f1]],\n",
    "            df.loc[(df['AD'] == 0) &(df['VD'] == 1)&(df['LBD'] == 0)][[f2]], \n",
    "             marker='<', alpha = 0.5, s =s, color = '#D62728')\n",
    "\n",
    "axs[0].scatter(df.loc[(df['AD'] == 1) &(df['VD'] == 0)&(df['LBD'] == 0)][[f1]],\n",
    "            df.loc[(df['AD'] == 1) &(df['VD'] == 0)&(df['LBD'] == 0)][[f2]], \n",
    "             marker='>', alpha = 0.5, s =s, color = '#2CA02C')\n",
    "\n",
    "axs[0].set_xlabel(r'$\\bf{AD}$ Probability', fontsize = fs)\n",
    "axs[0].set_ylabel(r'$\\bf{VD}$ Probability', fontsize = fs)    \n",
    "\n",
    "\n",
    "\n",
    "f1,f2 ='probAD','probLBD'\n",
    "axs[1].scatter(df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 0)][[f1]],\n",
    "            df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 0)][[f2]], \n",
    "            marker='o', alpha = 0.3, s =40, color = 'gray')\n",
    "\n",
    "axs[1].scatter(df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 1)][[f1]],\n",
    "            df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 1)][[f2]], \n",
    "             marker='^', alpha = 0.5, s =s, color = 'blue')\n",
    "\n",
    "axs[1].scatter(df.loc[(df['AD'] == 1) &(df['VD'] == 0)&(df['LBD'] == 0)][[f1]],\n",
    "            df.loc[(df['AD'] == 1) &(df['VD'] == 0)&(df['LBD'] == 0)][[f2]], \n",
    "            marker='>', alpha = 0.5, s =s, color = 'green')\n",
    "\n",
    "axs[1].scatter(df.loc[(df['AD'] == 1) &(df['VD'] == 0)&(df['LBD'] == 1)][[f1]],\n",
    "            df.loc[(df['AD'] == 1) &(df['VD'] == 0)&(df['LBD'] == 1)][[f2]], \n",
    "             marker='+', alpha = 0.5, s =s+100, color = 'purple')\n",
    "\n",
    "axs[1].scatter(df.loc[(df['AD'] == 1) &(df['VD'] == 1)&(df['LBD'] == 1)][[f1]],\n",
    "            df.loc[(df['AD'] == 1) &(df['VD'] == 1)&(df['LBD'] == 1)][[f2]], \n",
    "             marker='x', alpha = 0.5, s =s, color = 'goldenrod')\n",
    "\n",
    "axs[1].set_xlabel(r'$\\bf{AD}$ Probability', fontsize = fs)\n",
    "axs[1].set_ylabel(r'$\\bf{LBD}$ Probability', fontsize = fs) \n",
    "\n",
    "\n",
    "f1,f2 ='probVD','probLBD'\n",
    "axs[2].scatter(df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 0)][[f1]],\n",
    "            df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 0)][[f2]], \n",
    "            marker='o', alpha = 0.3, s =40, color = 'gray')\n",
    "\n",
    "axs[2].scatter(df.loc[(df['AD'] == 0) &(df['VD'] == 1)&(df['LBD'] == 0)][[f1]],\n",
    "            df.loc[(df['AD'] == 0) &(df['VD'] == 1)&(df['LBD'] == 0)][[f2]], \n",
    "            marker='<', alpha = 0.5, s =s, color = '#D62728')\n",
    "\n",
    "axs[2].scatter(df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 1)][[f1]],\n",
    "            df.loc[(df['AD'] == 0) &(df['VD'] == 0)&(df['LBD'] == 1)][[f2]], \n",
    "            marker='^', alpha = 0.5, s =s, color = 'blue')\n",
    "\n",
    "axs[2].scatter(df.loc[(df['AD'] == 0) &(df['VD'] == 1)&(df['LBD'] == 1)][[f1]],\n",
    "            df.loc[(df['AD'] == 0) &(df['VD'] == 1)&(df['LBD'] == 1)][[f2]], \n",
    "             marker='+', alpha = 0.5, s =s+100, color = 'magenta')\n",
    "\n",
    "axs[2].scatter(df.loc[(df['AD'] == 1) &(df['VD'] == 1)&(df['LBD'] == 1)][[f1]],\n",
    "            df.loc[(df['AD'] == 1) &(df['VD'] == 1)&(df['LBD'] == 1)][[f2]], \n",
    "             marker='x', alpha = 0.5, s =s, color = 'goldenrod')\n",
    "\n",
    "axs[2].set_xlabel( r'$\\bf{VD}$ Probability', fontsize = fs)\n",
    "axs[2].set_ylabel(r'$\\bf{LBD}$ Probability', fontsize = fs)\n",
    "    \n",
    "\n",
    "\n",
    "# plt.xlim([-0.05,1.05])\n",
    "# plt.ylim([-0.05,1.05])\n",
    "# plt.gca().set_yticklabels([f'{x:.0%}' for x in plt.gca().get_yticks()]) \n",
    "# plt.gca().set_xticklabels([f'{x:.0%}' for x in plt.gca().get_xticks()]) \n",
    "\n",
    "# axs[0].set_title(\"Deep Learning Chart\", fontsize = 20)\n",
    "# plt.grid(linestyle = '--')\n",
    "for i in range(0,3):\n",
    "    axs[i].axvline(x = 0.5, linestyle = '--', color='gray', alpha = 0.5)\n",
    "    axs[i].axhline(y = 0.5, linestyle = '--', color='gray', alpha = 0.5)\n",
    "    axs[i].set_xlim([-0.05,1.05])\n",
    "    axs[i].set_ylim([-0.05,1.05])\n",
    "    \n",
    "for i in range(0,3):    \n",
    "    axs[i].set_yticklabels([f'{x:.0%}' for x in plt.gca().get_yticks()], fontsize=12) \n",
    "    axs[i].set_xticklabels([f'{x:.0%}' for x in plt.gca().get_xticks()], fontsize=12) \n",
    "\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24991e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c32d0d4",
   "metadata": {},
   "source": [
    "# Plot SVM coefficient Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f7a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc45f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = '/media/dw/Data/BINC_T1/BINC/dropbox/DW/data_npy/T1_3DSminmax_ADVDLBD_Mlabel_10fold_0307v2/SVM/SVM_c0.01_'\n",
    "ad_coef = np.zeros((65,77,65))\n",
    "vd_coef = np.zeros((65,77,65))\n",
    "lbd_coef = np.zeros((65,77,65))\n",
    "for i in range(0,10):\n",
    "    ad_coef += np.load(pth + \"ad_coef\"+str(i)+\".npy\").reshape((65,77,65))\n",
    "    vd_coef += np.load(pth + \"vd_coef\"+str(i)+\".npy\").reshape((65,77,65))\n",
    "    lbd_coef += np.load(pth + \"lbd_coef\"+str(i)+\".npy\").reshape((65,77,65))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d8108",
   "metadata": {},
   "outputs": [],
   "source": [
    "mni = nib.load('/home/dw/Desktop/tools/mni_icbm152_nlin_sym_09c/d3_mni.nii')\n",
    "mni_affine = mni.affine\n",
    "mni_affine\n",
    "mn = mni.get_fdata()\n",
    "mn[mni == 0] = 'nan'\n",
    "\n",
    "mask = nib.load('/home/dw/Desktop/tools/mni_icbm152_nlin_sym_09c/d3_mask.nii.gz')\n",
    "mask = mask.get_fdata()\n",
    "mask[mask > 0] = 1\n",
    "mask_bool =mask.astype(bool)\n",
    "\n",
    "coord_MRI = (-33,-30,-28,-26,-22,-18,-12,-8,-5,-3,1)\n",
    "\n",
    "import matplotlib.colors as colors\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=1000):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap\n",
    "\n",
    "\n",
    "cmap = plt.get_cmap('hot_r') #   \n",
    "new_cmap = truncate_colormap(cmap, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b667a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,2))\n",
    "m = ad_coef\n",
    "m = abs(m)\n",
    "m = gaussian_filter(m,sigma=0.8)\n",
    "m = m*mask\n",
    "max_ = np.max(m)\n",
    "m = m/max_\n",
    "\n",
    "mii = nib.Nifti1Image(m, affine = mni_affine)\n",
    "\n",
    "plotting.plot_stat_map(mii, display_mode='z',cmap = new_cmap,threshold = 0,\n",
    "                   bg_img = mni,annotate=False,black_bg=False, \n",
    "                   colorbar=True, figure = fig, \n",
    "#                    title = \"SVM coefficient AD\",\n",
    "                   cut_coords=coord_MRI, draw_cross = False, alpha=0.7)\n",
    "\n",
    "fig = plt.figure(figsize = (16,2))\n",
    "m = vd_coef\n",
    "m = abs(m)\n",
    "m = gaussian_filter(m,sigma=0.8)\n",
    "m = m*mask\n",
    "max_ = np.max(m)\n",
    "m = m/max_\n",
    "\n",
    "mii = nib.Nifti1Image(m, affine = mni_affine)\n",
    "\n",
    "plotting.plot_stat_map(mii, display_mode='z',cmap = new_cmap,threshold = 0,\n",
    "                   bg_img = mni,annotate=False,black_bg=False, \n",
    "                   colorbar=True, figure = fig, \n",
    "#                    title = \"SVM coefficient VD\",\n",
    "                   cut_coords=coord_MRI, draw_cross = False, alpha=0.7)\n",
    "\n",
    "fig = plt.figure(figsize = (16,2))\n",
    "m = lbd_coef\n",
    "m = abs(m)\n",
    "m = gaussian_filter(m,sigma=0.8)\n",
    "m = m*mask\n",
    "max_ = np.max(m)\n",
    "m = m/max_\n",
    "\n",
    "mii = nib.Nifti1Image(m, affine = mni_affine)\n",
    "\n",
    "plotting.plot_stat_map(mii, display_mode='z',cmap = new_cmap,threshold = 0,\n",
    "                   bg_img = mni,annotate=False,black_bg=False, \n",
    "                   colorbar=True, figure = fig, \n",
    "#                    title = \"SVM coefficient LBD\",\n",
    "                   cut_coords=coord_MRI, draw_cross = False, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c9c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c23fd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ad8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
