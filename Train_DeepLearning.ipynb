{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1d02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "from mytools.utils import *\n",
    "import pathlib, sys, os\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_score,f1_score,roc_auc_score\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'T1_ADVDLBD_Mlabel_10fold_Match0307v2' \n",
    "which_model = 'resnet18_64_linear'   \n",
    "b_size = int(8) \n",
    "gpu_device = int(0)\n",
    "loss_name = 'ASL_4_1_0.1'\n",
    "data_folder = '/home/dw/Desktop/DemCLF/data/data_Mlabel_10fold_0307/'\n",
    "learning_rate = float(0.0001)\n",
    "norm = 'minmax'\n",
    "sigma = float(0.1)\n",
    "n_epochs = 300\n",
    "downsample =  '3DS'\n",
    "data_path = '/media/dw/Data/BINC_T1/BINC/dropbox/nacc_harmonized_may023//beforeHarm_' + downsample +norm+'/'\n",
    "wd=0.001\n",
    "labels = [\"AD\",\"VD\",\"LBD\"]\n",
    "clf_class = 3\n",
    "device = torch.device(gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f3807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainkfold(train = True, test= True, get_prob=True):\n",
    "    for fold in range(0,10):\n",
    "        print(fold)\n",
    "\n",
    "        ####################################\n",
    "        ########## get resnet ##############\n",
    "        ####################################\n",
    "        m = which_model.split(\"_\")[0]\n",
    "        channel = int(which_model.split(\"_\")[1])\n",
    "        res_head = which_model.split(\"_\")[2]\n",
    "        model = get_resnet(m, channel, clf_class, res_head)\n",
    "        model = model.to(device)\n",
    "\n",
    "        if 'he' in which_model:\n",
    "            print('he init')\n",
    "            model.apply(init_he)\n",
    "\n",
    "\n",
    "        ############################################\n",
    "        ########## set up save folder ##############\n",
    "        ############################################\n",
    "\n",
    "        if loss_name.startswith('ASL'):\n",
    "            gn,gp,c = int(loss_name.split(\"_\")[1]), int(loss_name.split(\"_\")[2]),float(loss_name.split(\"_\")[3])\n",
    "            criterion = AsymmetricLossOptimized(gamma_neg=gn, gamma_pos=gp,clip= c ).to(device)\n",
    "            model_pth = \"/media/dw/Data/BINC_T1/BINC/dropbox/DW/results_GenieCode/task2_\" + \\\n",
    "                data_name + \"_\" + downsample + norm+\"_OTF/\" + which_model+ \"_mlr\" + str(learning_rate) + \\\n",
    "                \"_ep\" + str(n_epochs)  + '_batch' + str(b_size)+ \"_ASL_gn\" + str(gn) + \"_gp\" + str(gp) + \\\n",
    "                \"_c\" + str(c)+ \"_sigma\" + str(sigma) + \"_wd\"+str(wd) +\"/\"\n",
    "        if loss_name == 'BCE':\n",
    "            criterion = nn.BCELoss().to(device)\n",
    "            model_pth = \"/media/dw/Data/BINC_T1/BINC/dropbox/DW/results_GenieCode/task2_\" + data_name + \"_\" + downsample + norm+\"_OTF/\" + which_model+ \"_mlr\" + str(learning_rate) + \\\n",
    "                    \"_ep\" + str(n_epochs)  + '_batch' + str(b_size)+ \"_\"+ loss_name+ \"_sigma\" + str(sigma) + \"_wd\" + str(wd)+ \"/\"\n",
    "\n",
    "\n",
    "\n",
    "        pathlib.Path(model_pth).mkdir(parents=True, exist_ok=True)\n",
    "        print(model_pth)\n",
    "\n",
    "\n",
    "        ########################################\n",
    "        ########## get dataloader ##############\n",
    "        ########################################\n",
    "\n",
    "        Train_set  = DatasetFromNiiOTF(data_path = data_path, csv_path= data_folder + '/'+ data_name + '_train_f'+ str(fold) + '.csv',\n",
    "                                    label=labels, sigma = sigma, ds = downsample)\n",
    "        Test_set  = DatasetFromNiiOTF(data_path = data_path, csv_path=  data_folder + '/'+ data_name + '_test_f'+ str(fold) + '.csv',\n",
    "                                    label=labels, sigma = 0, ds = downsample) ## sigma = 0 no augmentaion\n",
    "\n",
    "        Train_loader = torch.utils.data.DataLoader(Train_set, batch_size=b_size, num_workers=0, shuffle=True)\n",
    "        Test_loader = torch.utils.data.DataLoader(Test_set, batch_size=b_size, num_workers=0, shuffle=True)\n",
    "\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay = wd)\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[n_epochs//4,n_epochs//4*2,n_epochs//4*3], gamma=0.1)\n",
    "\n",
    "        save_name = 'fold'+str(fold)\n",
    "\n",
    "        ##################################\n",
    "        ########## Training ##############\n",
    "        ##################################\n",
    "        if train:\n",
    "            if os.path.isfile(model_pth + \"/\" + save_name + \"_target.npy\"):\n",
    "                pass\n",
    "            else:\n",
    "                fold_train_loss = []\n",
    "                for epoch in range(1, n_epochs+1):\n",
    "                    model_trained, epoch_train_loss = trainClass(Train_loader, model, criterion, optimizer,device, loss_name)\n",
    "                    print(epoch,epoch_train_loss/len(Train_set))\n",
    "                    scheduler.step()\n",
    "                    fold_train_loss.append(epoch_train_loss/len(Train_set))\n",
    "\n",
    "                torch.save(model_trained.state_dict(), model_pth + '/'+ save_name +'.pt')\n",
    "                df = pd.DataFrame(fold_train_loss)\n",
    "                df.to_csv(model_pth + \"/\" + save_name + \"_loss.csv\", index=False, header =None )\n",
    "\n",
    "        ###################################\n",
    "        ########### Testing ###############\n",
    "        ###################################\n",
    "        if test:\n",
    "            model_trained = model\n",
    "            model_trained.load_state_dict(torch.load(model_pth + '/'+ save_name +'.pt'))\n",
    "            model_trained.to(device)\n",
    "            model_trained.eval()\n",
    "            all_target = []\n",
    "            all_predict = []\n",
    "            all_probs = []\n",
    "            with torch.no_grad():\n",
    "                for j, (data, target, ids) in enumerate(Test_loader): \n",
    "                    torch.cuda.empty_cache() \n",
    "                    d,t = data.to(device), target.to(device, dtype=torch.float)\n",
    "                    all_target.extend(t.tolist())  # tensor to list\n",
    "                    ouput = model_trained(d)\n",
    "                    all_probs.extend(ouput.cpu().detach().tolist())\n",
    "                if \"Mlabel\" in data_name: \n",
    "                    for sample in all_probs:\n",
    "                        all_predict.append([1 if i>=0.5 else 0 for i in sample]) \n",
    "\n",
    "            np.save(model_pth + \"/\" + save_name + \"_predict.npy\", all_predict)\n",
    "            np.save(model_pth + \"/\" + save_name + \"_target.npy\", all_target)  \n",
    "\n",
    "        ###################################\n",
    "        ########### get Prob ##############\n",
    "        ###################################\n",
    "        if get_prob:\n",
    "            model_trained = model\n",
    "            model_trained.load_state_dict(torch.load(model_pth + '/'+ save_name +'.pt'))\n",
    "            model_trained.to(device)\n",
    "            model_trained.eval()\n",
    "\n",
    "            if \"ADFTD\" in data_name:\n",
    "                out_cols = ['outAD', 'outVD'] \n",
    "                prob_cols= ['probAD', 'probVD']\n",
    "            elif \"ADVDFTD\" in data_name:\n",
    "\n",
    "                prob_cols = ['probAD', 'probVD', 'probFTD']\n",
    "            elif \"ADVDLBD\" in data_name:\n",
    "                out_cols = ['outAD', 'outVD', 'outLBD'] \n",
    "                prob_cols = ['probAD', 'probVD', 'probLBD']\n",
    "            elif \"T1_Mlabel\" in data_name:\n",
    "                out_cols = ['outAD', 'outVD'] \n",
    "                prob_cols= ['probAD', 'probVD']\n",
    "            all_out = []\n",
    "            all_prob = []\n",
    "            all_label = []\n",
    "            all_tp = []\n",
    "            all_ids = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch, (data, target, ids) in enumerate(Test_loader):\n",
    "                    data = data.to(device, dtype = torch.float)\n",
    "                    out = model_trained(data)\n",
    "                    prob = nn.Sigmoid()(out)\n",
    "                    out = out.cpu().detach().tolist() \n",
    "                    prob = prob.cpu().detach().tolist() \n",
    "                    all_out.extend(out)\n",
    "                    all_prob.extend(prob)\n",
    "                    all_label.extend(target.cpu().detach().numpy())\n",
    "                    all_tp.extend(['test']*len(data))\n",
    "                    all_ids.extend(ids)\n",
    "\n",
    "            df = pd.DataFrame(all_prob, columns = ['probAD', 'probVD', 'probLBD'])\n",
    "            df2 = pd.DataFrame(all_label, columns = ['AD', 'VD', 'LBD'])\n",
    "            df.insert(loc = 0, column = 'mri_ID' , value = all_ids)\n",
    "            df.insert(loc = 1, column = 'tp' , value = all_tp)\n",
    "            df = pd.concat([df, df2], axis = 1)\n",
    "            df.to_csv(model_pth + save_name + \"_prob.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562a1803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfb4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c113d340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dddae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1dafe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
